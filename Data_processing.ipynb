{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1412771,"sourceType":"datasetVersion","datasetId":824374}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2 as cv\nimport pandas as pd\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom einops import rearrange\nfrom typing import List\nimport random\nimport math\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader \nfrom timm.utils import ModelEmaV3 \nfrom tqdm import tqdm \nimport matplotlib.pyplot as plt\nimport torch.optim as optim\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-09-09T20:11:40.553128Z","iopub.execute_input":"2024-09-09T20:11:40.553575Z","iopub.status.idle":"2024-09-09T20:11:56.960799Z","shell.execute_reply.started":"2024-09-09T20:11:40.553530Z","shell.execute_reply":"2024-09-09T20:11:56.959288Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"folder1 = '/kaggle/input/preprocessed-ct-scans-for-covid19/Original CT Scans/nCT'\nfolder2 = '/kaggle/input/preprocessed-ct-scans-for-covid19/Original CT Scans/pCT'\npositive = []\nnegative = []\nfor filename in os.listdir(folder2):\n    img_path = os.path.join(folder2, filename)\n    img = cv.imread(img_path)\n    img = cv.resize(img, (512, 512), interpolation = cv.INTER_CUBIC)\n    img = np.array(img,dtype='float64')\n    img/=np.max(img)\n    positive.append(img)\nfor filename in os.listdir(folder1):\n    img_path = os.path.join(folder1, filename)\n    img = cv.imread(img_path)\n    img = cv.resize(img, (512, 512), interpolation = cv.INTER_CUBIC)\n    img = np.array(img,dtype='float64')\n    img/=np.max(img)\n    negative.append(img)\npositive = np.array(positive)\nnegative = np.array(negative)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T20:18:05.054867Z","iopub.execute_input":"2024-09-09T20:18:05.055481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SinusoidalEmbeddings(nn.Module):\n    def __init__(self, time_steps:int, embed_dim: int):\n        super().__init__()\n        position = torch.arange(time_steps).unsqueeze(1).float()\n        div = torch.exp(torch.arange(0, embed_dim, 2).float() * -(math.log(10000.0) / embed_dim))\n        embeddings = torch.zeros(time_steps, embed_dim, requires_grad=False)\n        embeddings[:, 0::2] = torch.sin(position * div)\n        embeddings[:, 1::2] = torch.cos(position * div)\n        self.embeddings = embeddings\n\n    def forward(self, x, t):\n        embeds = self.embeddings[t].to(x.device)\n        return embeds[:, :, None, None]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResBlock(nn.Module):\n    def __init__(self, C: int, num_groups: int, dropout_prob: float):\n        super().__init__()\n        self.relu = nn.ReLU(inplace=True)\n        self.gnorm1 = nn.GroupNorm(num_groups=num_groups, num_channels=C)\n        self.gnorm2 = nn.GroupNorm(num_groups=num_groups, num_channels=C)\n        self.conv1 = nn.Conv2d(C, C, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(C, C, kernel_size=3, padding=1)\n        self.dropout = nn.Dropout(p=dropout_prob, inplace=True)\n\n    def forward(self, x, embeddings):\n        x = x + embeddings[:, :x.shape[1], :, :]\n        r = self.conv1(self.relu(self.gnorm1(x)))\n        r = self.dropout(r)\n        r = self.conv2(self.relu(self.gnorm2(r)))\n        return r + x","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(self, C: int, num_heads:int , dropout_prob: float):\n        super().__init__()\n        self.proj1 = nn.Linear(C, C*3)\n        self.proj2 = nn.Linear(C, C)\n        self.num_heads = num_heads\n        self.dropout_prob = dropout_prob\n\n    def forward(self, x):\n        h, w = x.shape[2:]\n        x = rearrange(x, 'b c h w -> b (h w) c')\n        x = self.proj1(x)\n        x = rearrange(x, 'b L (C H K) -> K b H L C', K=3, H=self.num_heads)\n        q,k,v = x[0], x[1], x[2]\n        x = F.scaled_dot_product_attention(q,k,v, is_causal=False, dropout_p=self.dropout_prob)\n        x = rearrange(x, 'b H (h w) C -> b h w (C H)', h=h, w=w)\n        x = self.proj2(x)\n        return rearrange(x, 'b h w C -> b C h w')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UnetLayer(nn.Module):\n    def __init__(self, \n            upscale: bool, \n            attention: bool, \n            num_groups: int, \n            dropout_prob: float,\n            num_heads: int,\n            C: int):\n        super().__init__()\n        self.ResBlock1 = ResBlock(C=C, num_groups=num_groups, dropout_prob=dropout_prob)\n        self.ResBlock2 = ResBlock(C=C, num_groups=num_groups, dropout_prob=dropout_prob)\n        if upscale:\n            self.conv = nn.ConvTranspose2d(C, C//2, kernel_size=4, stride=2, padding=1)\n        else:\n            self.conv = nn.Conv2d(C, C*2, kernel_size=3, stride=2, padding=1)\n        if attention:\n            self.attention_layer = Attention(C, num_heads=num_heads, dropout_prob=dropout_prob)\n\n    def forward(self, x, embeddings):\n        x = self.ResBlock1(x, embeddings)\n        if hasattr(self, 'attention_layer'):\n            x = self.attention_layer(x)\n        x = self.ResBlock2(x, embeddings)\n        return self.conv(x), x","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UNET(nn.Module):\n    def __init__(self,\n            Channels: List = [64, 128, 256, 512, 512, 384],\n            Attentions: List = [False, True, False, False, False, True],\n            Upscales: List = [False, False, False, True, True, True],\n            num_groups: int = 32,\n            dropout_prob: float = 0.1,\n            num_heads: int = 8,\n            input_channels: int = 1,\n            output_channels: int = 1,\n            time_steps: int = 1000):\n        super().__init__()\n        self.num_layers = len(Channels)\n        self.shallow_conv = nn.Conv2d(input_channels, Channels[0], kernel_size=3, padding=1)\n        out_channels = (Channels[-1]//2)+Channels[0]\n        self.late_conv = nn.Conv2d(out_channels, out_channels//2, kernel_size=3, padding=1)\n        self.output_conv = nn.Conv2d(out_channels//2, output_channels, kernel_size=1)\n        self.relu = nn.ReLU(inplace=True)\n        self.embeddings = SinusoidalEmbeddings(time_steps=time_steps, embed_dim=max(Channels))\n        for i in range(self.num_layers):\n            layer = UnetLayer(\n                upscale=Upscales[i],\n                attention=Attentions[i],\n                num_groups=num_groups,\n                dropout_prob=dropout_prob,\n                C=Channels[i],\n                num_heads=num_heads\n            )\n            setattr(self, f'Layer{i+1}', layer)\n\n    def forward(self, x, t):\n        x = self.shallow_conv(x)\n        residuals = []\n        for i in range(self.num_layers//2):\n            layer = getattr(self, f'Layer{i+1}')\n            embeddings = self.embeddings(x, t)\n            x, r = layer(x, embeddings)\n            residuals.append(r)\n        for i in range(self.num_layers//2, self.num_layers):\n            layer = getattr(self, f'Layer{i+1}')\n            x = torch.concat((layer(x, embeddings)[0], residuals[self.num_layers-i-1]), dim=1)\n        return self.output_conv(self.relu(self.late_conv(x)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DDPM_Scheduler(nn.Module):\n    def __init__(self, num_time_steps: int=1000):\n        super().__init__()\n        self.beta = torch.linspace(1e-4, 0.02, num_time_steps, requires_grad=False)\n        alpha = 1 - self.beta\n        self.alpha = torch.cumprod(alpha, dim=0).requires_grad_(False)\n\n    def forward(self, t):\n        return self.beta[t], self.alpha[t]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(batch_size: int=64,\n          num_time_steps: int=1000,\n          num_epochs: int=15,\n          seed: int=-1,\n          ema_decay: float=0.9999,  \n          lr=2e-5,\n          checkpoint_path: str=None):\n    set_seed(random.randint(0, 2**32-1)) if seed == -1 else set_seed(seed)\n\n    train_dataset = datasets.MNIST(root='./data', train=True, download=False,transform=transforms.ToTensor())\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=4)\n\n    scheduler = DDPM_Scheduler(num_time_steps=num_time_steps)\n    model = UNET().cuda()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    ema = ModelEmaV3(model, decay=ema_decay)\n    if checkpoint_path is not None:\n        checkpoint = torch.load(checkpoint_path)\n        model.load_state_dict(checkpoint['weights'])\n        ema.load_state_dict(checkpoint['ema'])\n        optimizer.load_state_dict(checkpoint['optimizer'])\n    criterion = nn.MSELoss(reduction='mean')\n\n    for i in range(num_epochs):\n        total_loss = 0\n        for bidx, (x,_) in enumerate(tqdm(train_loader, desc=f\"Epoch {i+1}/{num_epochs}\")):\n            x = x.cuda()\n            x = F.pad(x, (2,2,2,2))\n            t = torch.randint(0,num_time_steps,(batch_size,))\n            e = torch.randn_like(x, requires_grad=False)\n            a = scheduler.alpha[t].view(batch_size,1,1,1).cuda()\n            x = (torch.sqrt(a)*x) + (torch.sqrt(1-a)*e)\n            output = model(x, t)\n            optimizer.zero_grad()\n            loss = criterion(output, e)\n            total_loss += loss.item()\n            loss.backward()\n            optimizer.step()\n            ema.update(model)\n        print(f'Epoch {i+1} | Loss {total_loss / (60000/batch_size):.5f}')\n\n    checkpoint = {\n        'weights': model.state_dict(),\n        'optimizer': optimizer.state_dict(),\n        'ema': ema.state_dict()\n    }\n    torch.save(checkpoint, 'checkpoints/ddpm_checkpoint')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}